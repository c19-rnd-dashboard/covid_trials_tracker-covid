{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICTRP Search: \"covid-19\" or \"novel coronavirus\" or \"2019-ncov\" or \"covid19\" or \"sars-cov-2\"\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import unicodedata\n",
    "\n",
    "#POINT THIS TO THE UPDATED XML\n",
    "with open('ICTRP-Results_18Mar2020.xml', 'rb') as f:\n",
    "    xml = xmltodict.parse(f, dict_constructor=dict)\n",
    "\n",
    "df = pd.DataFrame(xml['Trials_downloaded_from_ICTRP']['Trial'])\n",
    "\n",
    "\n",
    "#UPDATE THESE WITH EACH RUN\n",
    "prior_extract_date = date(2020,3,18)\n",
    "this_extract_date = date(2020,3,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search on ICTRP reveals 578 trials as of 2020-03-18\n"
     ]
    }
   ],
   "source": [
    "#For future:\n",
    "#Can try and parse the 'Target_size' variable, difficult for the Chinese registry\n",
    "\n",
    "cols = ['TrialID', 'Source_Register', 'Date_registration', 'Date_enrollement', 'Primary_sponsor', \n",
    "        'Recruitment_Status', 'Phase', 'Study_type', 'Countries', 'Public_title', 'Intervention',\n",
    "        'web_address', 'results_url_link', 'Last_Refreshed_on']\n",
    "\n",
    "df_cond = df[cols].reset_index(drop=True)\n",
    "\n",
    "print(f'Search on ICTRP reveals {len(df_cond)} trials as of {this_extract_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POINT THIS TO LAST WEEK'S DATA\n",
    "last_weeks_trials = pd.read_csv('trials_8_mar.csv')\n",
    "\n",
    "df_cond = df_cond.merge(last_weeks_trials[['trialid', 'first_seen']], left_on = 'TrialID', right_on = 'trialid', \n",
    "                        how='left').drop('trialid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For next time\n",
    "#df_cond['first_seen'].fillna(pd.Timestamp(this_extract_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChiCTR                476\n",
       "ClinicalTrials.gov    102\n",
       "Name: Source_Register, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for which registries we are dealing with:\n",
    "df_cond.Source_Register.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first area where we may need manual intervention on updates. As more registries start to appear, there may be dates in new formats that we need to address. Just running a date parse over the column, even with just two registries, was already producing wonky dates so I had to split it by registry. Check this based on the registries above and adjust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last refreshed date parse\n",
    "df_cond['Last_Refreshed_on'] = pd.to_datetime(df_cond['Last_Refreshed_on'])\n",
    "\n",
    "#cleaning up registration dates\n",
    "\n",
    "date_parsing_reg = df_cond[['TrialID', 'Date_registration']].reset_index(drop=True)\n",
    "\n",
    "ncts = date_parsing_reg[date_parsing_reg['TrialID'].str.contains('NCT')].reset_index(drop=True)\n",
    "ncts['parsed_date'] = pd.to_datetime(ncts['Date_registration'], format='%d/%m/%Y')\n",
    "\n",
    "chictr = date_parsing_reg[date_parsing_reg['TrialID'].str.contains('Chi')].reset_index(drop=True)\n",
    "chictr['parsed_date'] = pd.to_datetime(chictr['Date_registration'], format='%Y-%m-%d')\n",
    "\n",
    "nct_merged_reg = df_cond.merge(ncts[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "chi_merged_reg = nct_merged_reg.merge(chictr[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "\n",
    "df_cond['Date_registration'] = chi_merged_reg['parsed_date_x'].fillna(chi_merged_reg['parsed_date_y'])\n",
    "\n",
    "#cleaning up start dates\n",
    "\n",
    "date_parsing_enr = df_cond[['TrialID', 'Date_enrollement']].reset_index(drop=True)\n",
    "\n",
    "ncts = date_parsing_enr[date_parsing_enr['TrialID'].str.contains('NCT')].reset_index(drop=True)\n",
    "ncts['parsed_date'] = pd.to_datetime(ncts['Date_enrollement'])\n",
    "\n",
    "chictr = date_parsing_enr[date_parsing_enr['TrialID'].str.contains('Chi')].reset_index(drop=True)\n",
    "chictr['parsed_date'] = pd.to_datetime(chictr['Date_enrollement'], format='%Y-%m-%d')\n",
    "\n",
    "nct_merged_enr = df_cond.merge(ncts[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "chi_merged_enr = nct_merged_enr.merge(chictr[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "\n",
    "df_cond['Date_enrollement'] = chi_merged_enr['parsed_date_x'].fillna(chi_merged_enr['parsed_date_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 6 trials from before 2020\n",
      "572 trials remain\n"
     ]
    }
   ],
   "source": [
    "#lets get rid of trials from before 2020 for now\n",
    "\n",
    "pre_2020 = len(df_cond[df_cond['Date_registration'] < pd.Timestamp(2020,1,1)])\n",
    "\n",
    "print(f'Excluded {pre_2020} trials from before 2020')\n",
    "\n",
    "df_cond_rec = df_cond[df_cond['Date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_rec)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 2 for manual intervention. As more registries add trials, we will have to contend with a wider vocabulary/identification methods for trials that are cancelled/withdrawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 37 cancelled trials with no enrollment\n",
      "535 trials remain\n"
     ]
    }
   ],
   "source": [
    "#Removing cancelled/withdrawn trials for what registries we have to date\n",
    "\n",
    "cancelled_trials = len(df_cond_rec[(df_cond_rec['Public_title'].str.contains('Cancelled')) | \n",
    "                         (df_cond_rec['Recruitment_Status'] == \"Withdrawn\")])\n",
    "\n",
    "print(f'Excluded {cancelled_trials} cancelled trials with no enrollment')\n",
    "\n",
    "df_cond_nc = df_cond_rec[~(df_cond_rec['Public_title'].str.contains('Cancelled')) & \n",
    "                         ~(df_cond_rec['Recruitment_Status'] == \"Withdrawn\")].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_nc)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point three for manual intervention. All this normalisation and data cleaning will have to be expanded each update as more trials get added and more registries start to add trials with their own idiosyncratic data categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Observational study', 'Interventional study', 'Diagnostic test',\n",
       "       'Basic Science', 'Interventional', 'Observational', 'Prevention',\n",
       "       'Prognosis study', 'Epidemilogical research', 'Treatment study',\n",
       "       'Expanded Access', 'Health services reaserch',\n",
       "       'Observational [Patient Registry]', 'Screening'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_fields(field):\n",
    "    return df_cond_nc[field].unique()\n",
    "\n",
    "#Check fields for new unique values that require normalisation\n",
    "check_fields('Study_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More data cleaning\n",
    "\n",
    "#semi-colons in the intervention field mess with CSV\n",
    "df_cond_nc['Intervention'] = df_cond_nc['Intervention'].str.replace(';', '')\n",
    "\n",
    "#Study Type\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].str.replace(' study', '')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace('Observational [Patient Registry]', 'Observational')\n",
    "\n",
    "#Recruitment Status\n",
    "df_cond_nc['Recruitment_Status'] = df_cond_nc['Recruitment_Status'].replace('Not recruiting', 'Not Recruiting')\n",
    "\n",
    "#Countries\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].fillna('No Country Given')\n",
    "\n",
    "china_corr = ['Chian', 'China?', 'Chinese', 'Wuhan', 'Chinaese', 'china']\n",
    "\n",
    "for c in china_corr:\n",
    "    df_cond_nc['Countries'] = df_cond_nc['Countries'].replace(c, 'China')\n",
    "    \n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].replace('United States;Korea, Republic of;United States', \n",
    "                                                          'South Korea; United States')\n",
    "\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].replace('Korea, Republic of', 'South Korea')\n",
    "\n",
    "#Normalize Sponsor name\n",
    "\n",
    "def norm_names(x):\n",
    "    normed = unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore').decode()\n",
    "    return normed \n",
    "\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc.Primary_sponsor.apply(norm_names)\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc['Primary_sponsor'].replace('NA', 'No Sponsor Name Given')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last space for manual intervention. This will include manual normalisation of new names, any updates to the normalisation schedule from the last update, and updating manually-coded intervention type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sponsor names normalized\n"
     ]
    }
   ],
   "source": [
    "#Normalizing sponsor names\n",
    "#Run this cell, updating the spon_norm csv you are loading after manual adjusting\n",
    "#until you get the 'All sponsor names normalized' to print\n",
    "\n",
    "spon_norm = pd.read_csv('norm_schedule_18Mar2020.csv')\n",
    "\n",
    "df_cond_norm = df_cond_nc.merge(spon_norm, left_on = 'Primary_sponsor', right_on ='unique_spon_names', how='left')\n",
    "df_cond_norm = df_cond_norm.drop('unique_spon_names', axis=1)\n",
    "\n",
    "new_unique_spon_names = (df_cond_norm[df_cond_norm['normed_spon_names'].isna()][['Primary_sponsor', 'TrialID']]\n",
    "                        .groupby('Primary_sponsor').count())\n",
    "\n",
    "if len(new_unique_spon_names) > 0:\n",
    "    new_unique_spon_names.to_csv('to_norm.csv')\n",
    "    print('Update the normalisation schedule and rerun')\n",
    "else:\n",
    "    print('All sponsor names normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the intervention type assessments and rerun\n"
     ]
    }
   ],
   "source": [
    "#Integrating intervention type data\n",
    "#Once again, run to bring in the old int-type data, islolate the new ones, update, and rerun until\n",
    "#producing the all-clear message\n",
    "\n",
    "int_type = pd.read_csv('int_type_data_8mar2020.csv')\n",
    "df_cond_int = df_cond_norm.merge(int_type, left_on = 'TrialID', right_on = 'trial_id', how='left')\n",
    "df_cond_int = df_cond_int.drop('trial_id', axis=1)\n",
    "\n",
    "new_int_trials = df_cond_int[df_cond_int['intervention_type'].isna()]\n",
    "\n",
    "if len(new_int_trials) > 0:\n",
    "    new_int_trials[['TrialID', 'Public_title', 'Intervention', 'intervention_type']].to_csv('int_to_assess.csv')\n",
    "    print('Update the intervention type assessments and rerun')\n",
    "else:\n",
    "    print('All intervention types matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialID</th>\n",
       "      <th>Source_Register</th>\n",
       "      <th>Date_registration</th>\n",
       "      <th>Date_enrollement</th>\n",
       "      <th>Primary_sponsor</th>\n",
       "      <th>Recruitment_Status</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Study_type</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Public_title</th>\n",
       "      <th>Intervention</th>\n",
       "      <th>web_address</th>\n",
       "      <th>results_url_link</th>\n",
       "      <th>Last_Refreshed_on</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>normed_spon_names</th>\n",
       "      <th>intervention_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TrialID, Source_Register, Date_registration, Date_enrollement, Primary_sponsor, Recruitment_Status, Phase, Study_type, Countries, Public_title, Intervention, web_address, results_url_link, Last_Refreshed_on, first_seen, normed_spon_names, intervention_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a quick glance at old trials that updated\n",
    "\n",
    "df_cond_int[(df_cond_int['Last_Refreshed_on'] > pd.Timestamp(prior_extract_date)) & \n",
    "            (df_cond_int['first_seen'] != this_extract_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_int.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_int.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'normed_spon_names', \n",
    "           'recruitment_status', 'phase', 'study_type', 'countries', 'public_title', 'intervention_type', \n",
    "           'web_address', 'results_url_link', 'last_refreshed_on', 'first_seen']\n",
    "\n",
    "df_final = df_cond_int[reorder].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final.to_csv(f'trial_list_{this_extract_date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialid</th>\n",
       "      <th>source_register</th>\n",
       "      <th>date_registration</th>\n",
       "      <th>date_enrollement</th>\n",
       "      <th>normed_spon_names</th>\n",
       "      <th>recruitment_status</th>\n",
       "      <th>phase</th>\n",
       "      <th>study_type</th>\n",
       "      <th>countries</th>\n",
       "      <th>public_title</th>\n",
       "      <th>intervention_type</th>\n",
       "      <th>web_address</th>\n",
       "      <th>results_url_link</th>\n",
       "      <th>last_refreshed_on</th>\n",
       "      <th>first_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChiCTR2000029953</td>\n",
       "      <td>ChiCTR</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zhongnan Hospital of Wuhan University</td>\n",
       "      <td>Not Recruiting</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Observational</td>\n",
       "      <td>China</td>\n",
       "      <td>Construction and Analysis of Prognostic Predic...</td>\n",
       "      <td>Prognosis</td>\n",
       "      <td>http://www.chictr.org.cn/showproj.aspx?proj=49217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>08/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChiCTR2000029935</td>\n",
       "      <td>ChiCTR</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>Hwa Mei Hospital, University of Chinese Academ...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>China</td>\n",
       "      <td>A Single-arm Clinical Trial for Chloroquine Ph...</td>\n",
       "      <td>Drug</td>\n",
       "      <td>http://www.chictr.org.cn/showproj.aspx?proj=49607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>08/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChiCTR2000029868</td>\n",
       "      <td>ChiCTR</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>Ruijin Hospital, Shanghai Jiaotong University ...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>4</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>China</td>\n",
       "      <td>Hydroxychloroquine treating novel coronavirus ...</td>\n",
       "      <td>Drug</td>\n",
       "      <td>http://www.chictr.org.cn/showproj.aspx?proj=49524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>08/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChiCTR2000029850</td>\n",
       "      <td>ChiCTR</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>The First Affiliated Hospital of Zhejiang Univ...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>0</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>China</td>\n",
       "      <td>Study on convalescent plasma treatment for sev...</td>\n",
       "      <td>ATMP</td>\n",
       "      <td>http://www.chictr.org.cn/showproj.aspx?proj=49533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>08/03/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChiCTR2000029814</td>\n",
       "      <td>ChiCTR</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>Children's Hospital of Fudan University</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>0</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>China</td>\n",
       "      <td>Clinical Trial for Integrated Chinese and West...</td>\n",
       "      <td>TCM + Western</td>\n",
       "      <td>http://www.chictr.org.cn/showproj.aspx?proj=49387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>08/03/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trialid source_register date_registration date_enrollement  \\\n",
       "0  ChiCTR2000029953          ChiCTR        2020-02-17       2020-02-01   \n",
       "1  ChiCTR2000029935          ChiCTR        2020-02-16       2020-02-06   \n",
       "2  ChiCTR2000029868          ChiCTR        2020-02-15       2020-02-10   \n",
       "3  ChiCTR2000029850          ChiCTR        2020-02-15       2020-02-15   \n",
       "4  ChiCTR2000029814          ChiCTR        2020-02-14       2020-02-14   \n",
       "\n",
       "                                   normed_spon_names recruitment_status phase  \\\n",
       "0              Zhongnan Hospital of Wuhan University     Not Recruiting   N/A   \n",
       "1  Hwa Mei Hospital, University of Chinese Academ...         Recruiting   N/A   \n",
       "2  Ruijin Hospital, Shanghai Jiaotong University ...         Recruiting     4   \n",
       "3  The First Affiliated Hospital of Zhejiang Univ...         Recruiting     0   \n",
       "4            Children's Hospital of Fudan University         Recruiting     0   \n",
       "\n",
       "       study_type countries  \\\n",
       "0   Observational     China   \n",
       "1  Interventional     China   \n",
       "2  Interventional     China   \n",
       "3  Interventional     China   \n",
       "4  Interventional     China   \n",
       "\n",
       "                                        public_title intervention_type  \\\n",
       "0  Construction and Analysis of Prognostic Predic...         Prognosis   \n",
       "1  A Single-arm Clinical Trial for Chloroquine Ph...              Drug   \n",
       "2  Hydroxychloroquine treating novel coronavirus ...              Drug   \n",
       "3  Study on convalescent plasma treatment for sev...              ATMP   \n",
       "4  Clinical Trial for Integrated Chinese and West...     TCM + Western   \n",
       "\n",
       "                                         web_address  results_url_link  \\\n",
       "0  http://www.chictr.org.cn/showproj.aspx?proj=49217               NaN   \n",
       "1  http://www.chictr.org.cn/showproj.aspx?proj=49607               NaN   \n",
       "2  http://www.chictr.org.cn/showproj.aspx?proj=49524               NaN   \n",
       "3  http://www.chictr.org.cn/showproj.aspx?proj=49533               NaN   \n",
       "4  http://www.chictr.org.cn/showproj.aspx?proj=49387               NaN   \n",
       "\n",
       "  last_refreshed_on  first_seen  \n",
       "0        2020-02-17  08/03/2020  \n",
       "1        2020-02-17  08/03/2020  \n",
       "2        2020-02-17  08/03/2020  \n",
       "3        2020-02-17  08/03/2020  \n",
       "4        2020-02-17  08/03/2020  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Trend in Registered Trials Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['TrialID', 'Date_registration'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-71b43f7e875e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#for the moment we aren't generating the final df yet so just pulling in the most complete so we can pass the tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#just_reg = df_final[['TrialID', 'Date_registration']].reset_index(drop=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjust_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cond_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrialID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date_registration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#catch old registrations that were expanded to include COVID, we can get rid of these for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1552\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['TrialID', 'Date_registration'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#for the moment we aren't generating the final df yet so just pulling in the most complete so we can pass the tests\n",
    "just_reg = df_final[['trialid, 'Date_registration']].reset_index(drop=True)\n",
    "\n",
    "#catch old registrations that were expanded to include COVID, we can get rid of these for now\n",
    "just_reg = just_reg[just_reg['Date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "just_reg.index = just_reg['Date_registration']\n",
    "\n",
    "\n",
    "grouped = just_reg.resample('W').count()\n",
    "cumsum = grouped.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = []\n",
    "\n",
    "for x in list(grouped.index):\n",
    "    labels.append(str(x.date()))\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5), dpi = 300)\n",
    "\n",
    "l1 = plt.plot(x_pos, grouped['TrialID'], marker = 'o')\n",
    "l2 = plt.plot(x_pos, cumsum['TrialID'], marker = 'o')\n",
    "\n",
    "for i, j in zip(x_pos[1:], grouped['TrialID'].tolist()[1:]):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.1, j-35))\n",
    "\n",
    "for i, j in zip(x_pos, cumsum['TrialID']):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.2, j+20))\n",
    "    \n",
    "\n",
    "gr = grouped['TrialID'].to_list()\n",
    "cs = cumsum['TrialID'].to_list()\n",
    "\n",
    "plt.xticks(x_pos, labels, rotation=45, fontsize=8)\n",
    "plt.ylim(-20,600)\n",
    "plt.xlabel('Week Ending Date')\n",
    "plt.ylabel('Registered Trials')\n",
    "plt.title('Registered COVID-19 Trials by Week on the ICTRP')\n",
    "plt.legend(('New Trials', 'Cumulative Trials'), loc=2)\n",
    "#plt.savefig(f'trial_count_{last_extract_date}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
