{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ICTRP Search: \"covid-19\" or \"novel coronavirus\" or \"2019-ncov\" or \"covid19\" or \"sars-cov-2\"\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import unicodedata\n",
    "\n",
    "#POINT THIS TO THE UPDATED XML\n",
    "with open('ICTRP-Results_18Mar2020.xml', 'rb') as f:\n",
    "    xml = xmltodict.parse(f, dict_constructor=dict)\n",
    "\n",
    "df = pd.DataFrame(xml['Trials_downloaded_from_ICTRP']['Trial'])\n",
    "\n",
    "\n",
    "#UPDATE THESE WITH EACH RUN\n",
    "prior_extract_date = date(2020,3,18)\n",
    "this_extract_date = date(2020,3,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For future:\n",
    "#Can try and parse the 'Target_size' variable, difficult for the Chinese registry\n",
    "\n",
    "cols = ['TrialID', 'Source_Register', 'Date_registration', 'Date_enrollement', 'Primary_sponsor', \n",
    "        'Recruitment_Status', 'Phase', 'Study_type', 'Countries', 'Public_title', 'Intervention',\n",
    "        'web_address', 'results_url_link', 'Last_Refreshed_on']\n",
    "\n",
    "df_cond = df[cols].reset_index(drop=True)\n",
    "\n",
    "print(f'Search on ICTRP reveals {len(df_cond)} trials as of {this_extract_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POINT THIS TO LAST WEEK'S DATA\n",
    "last_weeks_trials = pd.read_csv('trials_8_mar.csv')\n",
    "\n",
    "df_cond = df_cond.merge(last_weeks_trials[['trialid', 'first_seen']], left_on = 'TrialID', right_on = 'trialid', \n",
    "                        how='left').drop('trialid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For next time\n",
    "#df_cond['first_seen'].fillna(pd.Timestamp(this_extract_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for which registries we are dealing with:\n",
    "df_cond.Source_Register.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first area where we may need manual intervention on updates. As more registries start to appear, there may be dates in new formats that we need to address. Just running a date parse over the column, even with just two registries, was already producing wonky dates so I had to split it by registry. Check this based on the registries above and adjust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last refreshed date parse\n",
    "df_cond['Last_Refreshed_on'] = pd.to_datetime(df_cond['Last_Refreshed_on'])\n",
    "\n",
    "#cleaning up registration dates\n",
    "\n",
    "date_parsing_reg = df_cond[['TrialID', 'Date_registration']].reset_index(drop=True)\n",
    "\n",
    "ncts = date_parsing_reg[date_parsing_reg['TrialID'].str.contains('NCT')].reset_index(drop=True)\n",
    "ncts['parsed_date'] = pd.to_datetime(ncts['Date_registration'], format='%d/%m/%Y')\n",
    "\n",
    "chictr = date_parsing_reg[date_parsing_reg['TrialID'].str.contains('Chi')].reset_index(drop=True)\n",
    "chictr['parsed_date'] = pd.to_datetime(chictr['Date_registration'], format='%Y-%m-%d')\n",
    "\n",
    "nct_merged_reg = df_cond.merge(ncts[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "chi_merged_reg = nct_merged_reg.merge(chictr[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "\n",
    "df_cond['Date_registration'] = chi_merged_reg['parsed_date_x'].fillna(chi_merged_reg['parsed_date_y'])\n",
    "\n",
    "#cleaning up start dates\n",
    "\n",
    "date_parsing_enr = df_cond[['TrialID', 'Date_enrollement']].reset_index(drop=True)\n",
    "\n",
    "ncts = date_parsing_enr[date_parsing_enr['TrialID'].str.contains('NCT')].reset_index(drop=True)\n",
    "ncts['parsed_date'] = pd.to_datetime(ncts['Date_enrollement'])\n",
    "\n",
    "chictr = date_parsing_enr[date_parsing_enr['TrialID'].str.contains('Chi')].reset_index(drop=True)\n",
    "chictr['parsed_date'] = pd.to_datetime(chictr['Date_enrollement'], format='%Y-%m-%d')\n",
    "\n",
    "nct_merged_enr = df_cond.merge(ncts[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "chi_merged_enr = nct_merged_enr.merge(chictr[['TrialID','parsed_date']], on='TrialID', how='left')\n",
    "\n",
    "df_cond['Date_enrollement'] = chi_merged_enr['parsed_date_x'].fillna(chi_merged_enr['parsed_date_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get rid of trials from before 2020 for now\n",
    "\n",
    "pre_2020 = len(df_cond[df_cond['Date_registration'] < pd.Timestamp(2020,1,1)])\n",
    "\n",
    "print(f'Excluded {pre_2020} trials from before 2020')\n",
    "\n",
    "df_cond_rec = df_cond[df_cond['Date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_rec)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 2 for manual intervention. As more registries add trials, we will have to contend with a wider vocabulary/identification methods for trials that are cancelled/withdrawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing cancelled/withdrawn trials for what registries we have to date\n",
    "\n",
    "cancelled_trials = len(df_cond_rec[(df_cond_rec['Public_title'].str.contains('Cancelled')) | \n",
    "                         (df_cond_rec['Recruitment_Status'] == \"Withdrawn\")])\n",
    "\n",
    "print(f'Excluded {cancelled_trials} cancelled trials with no enrollment')\n",
    "\n",
    "df_cond_nc = df_cond_rec[~(df_cond_rec['Public_title'].str.contains('Cancelled')) & \n",
    "                         ~(df_cond_rec['Recruitment_Status'] == \"Withdrawn\")].reset_index(drop=True)\n",
    "\n",
    "print(f'{len(df_cond_nc)} trials remain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point three for manual intervention. All this normalisation and data cleaning will have to be expanded each update as more trials get added and more registries start to add trials with their own idiosyncratic data categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fields(field):\n",
    "    return df_cond_nc[field].unique()\n",
    "\n",
    "#Check fields for new unique values that require normalisation\n",
    "check_fields('Study_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More data cleaning\n",
    "\n",
    "#semi-colons in the intervention field mess with CSV\n",
    "df_cond_nc['Intervention'] = df_cond_nc['Intervention'].str.replace(';', '')\n",
    "\n",
    "#Study Type\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].str.replace(' study', '')\n",
    "df_cond_nc['Study_type'] = df_cond_nc['Study_type'].replace('Observational [Patient Registry]', 'Observational')\n",
    "\n",
    "#Recruitment Status\n",
    "df_cond_nc['Recruitment_Status'] = df_cond_nc['Recruitment_Status'].replace('Not recruiting', 'Not Recruiting')\n",
    "\n",
    "#Countries\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].fillna('No Country Given')\n",
    "\n",
    "china_corr = ['Chian', 'China?', 'Chinese', 'Wuhan', 'Chinaese', 'china']\n",
    "\n",
    "for c in china_corr:\n",
    "    df_cond_nc['Countries'] = df_cond_nc['Countries'].replace(c, 'China')\n",
    "    \n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].replace('United States;Korea, Republic of;United States', \n",
    "                                                          'South Korea; United States')\n",
    "\n",
    "df_cond_nc['Countries'] = df_cond_nc['Countries'].replace('Korea, Republic of', 'South Korea')\n",
    "\n",
    "#Normalize Sponsor name\n",
    "\n",
    "def norm_names(x):\n",
    "    normed = unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore').decode()\n",
    "    return normed \n",
    "\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc.Primary_sponsor.apply(norm_names)\n",
    "df_cond_nc['Primary_sponsor'] = df_cond_nc['Primary_sponsor'].replace('NA', 'No Sponsor Name Given')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last space for manual intervention. This will include manual normalisation of new names, any updates to the normalisation schedule from the last update, and updating manually-coded intervention type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing sponsor names\n",
    "#Run this cell, updating the spon_norm csv you are loading after manual adjusting\n",
    "#until you get the 'All sponsor names normalized' to print\n",
    "\n",
    "spon_norm = pd.read_csv('norm_schedule_18Mar2020.csv')\n",
    "\n",
    "df_cond_norm = df_cond_nc.merge(spon_norm, left_on = 'Primary_sponsor', right_on ='unique_spon_names', how='left')\n",
    "df_cond_norm = df_cond_norm.drop('unique_spon_names', axis=1)\n",
    "\n",
    "new_unique_spon_names = (df_cond_norm[df_cond_norm['normed_spon_names'].isna()][['Primary_sponsor', 'TrialID']]\n",
    "                        .groupby('Primary_sponsor').count())\n",
    "\n",
    "if len(new_unique_spon_names) > 0:\n",
    "    new_unique_spon_names.to_csv('to_norm.csv')\n",
    "    print('Update the normalisation schedule and rerun')\n",
    "else:\n",
    "    print('All sponsor names normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrating intervention type data\n",
    "#Once again, run to bring in the old int-type data, islolate the new ones, update, and rerun until\n",
    "#producing the all-clear message\n",
    "\n",
    "int_type = pd.read_csv('int_type_data_8mar2020.csv')\n",
    "df_cond_int = df_cond_norm.merge(int_type, left_on = 'TrialID', right_on = 'trial_id', how='left')\n",
    "df_cond_int = df_cond_int.drop('trial_id', axis=1)\n",
    "\n",
    "new_int_trials = df_cond_int[df_cond_int['intervention_type'].isna()]\n",
    "\n",
    "if len(new_int_trials) > 0:\n",
    "    new_int_trials[['TrialID', 'Public_title', 'Intervention', 'intervention_type']].to_csv('int_to_assess.csv')\n",
    "    print('Update the intervention type assessments and rerun')\n",
    "else:\n",
    "    print('All intervention types matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a quick glance at old trials that updated\n",
    "\n",
    "df_cond_int[(df_cond_int['Last_Refreshed_on'] > pd.Timestamp(prior_extract_date)) & \n",
    "            df_conf_int['first_seen'] != this_extract_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = []\n",
    "\n",
    "for col in list(df_cond_int.columns):\n",
    "    col_names.append(col.lower())\n",
    "    \n",
    "df_cond_norm.columns = col_names\n",
    "\n",
    "reorder = ['trialid', 'source_register', 'date_registration', 'date_enrollement', 'normed_spon_names', \n",
    "           'recruitment_status', 'phase', 'study_type', 'countries', 'public_title', 'intervention_type', \n",
    "           'web_address', 'results_url_link', 'last_refreshed_on', 'first_seen']\n",
    "\n",
    "df_final = df_cond_norm[reorder].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(f'trial_list_{this_extract_date}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Trend in Registered Trials Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_reg = df_final[['TrialID', 'Date_registration']].reset_index(drop=True)\n",
    "\n",
    "#catch old registrations that were expanded to include COVID, we can get rid of these for now\n",
    "just_reg = just_reg[just_reg['Date_registration'] >= pd.Timestamp(2020,1,1)].reset_index(drop=True)\n",
    "just_reg.index = just_reg['Date_registration']\n",
    "\n",
    "\n",
    "grouped = just_reg.resample('W').count()\n",
    "cumsum = grouped.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = []\n",
    "\n",
    "for x in list(grouped.index):\n",
    "    labels.append(str(x.date()))\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(labels)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5), dpi = 300)\n",
    "\n",
    "l1 = plt.plot(x_pos, grouped['TrialID'], marker = 'o')\n",
    "l2 = plt.plot(x_pos, cumsum['TrialID'], marker = 'o')\n",
    "\n",
    "for i, j in zip(x_pos[1:], grouped['TrialID'].tolist()[1:]):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.1, j-35))\n",
    "\n",
    "for i, j in zip(x_pos, cumsum['TrialID']):\n",
    "    ax.annotate(str(j), (i,j), xytext = (i-.2, j+20))\n",
    "    \n",
    "\n",
    "gr = grouped['TrialID'].to_list()\n",
    "cs = cumsum['TrialID'].to_list()\n",
    "\n",
    "plt.xticks(x_pos, labels, rotation=45, fontsize=8)\n",
    "plt.ylim(-20,600)\n",
    "plt.xlabel('Week Ending Date')\n",
    "plt.ylabel('Registered Trials')\n",
    "plt.title('Registered COVID-19 Trials by Week on the ICTRP')\n",
    "plt.legend(('New Trials', 'Cumulative Trials'), loc=2)\n",
    "#plt.savefig(f'trial_count_{last_extract_date}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
